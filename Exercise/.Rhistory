# The data parameter is a list of 10 groups and except is the number of the group to be excluded from tr. set
listToVectorExcept <- function(data, except){
value <- c()
for(i in 1:NROW(data)){
if(i != except){
value <- append(value, data[[i]])
}
}
return(value)
}
#ten.fold.split first divides the groups in equal divided groups of 20. The data is already random, so we do not make it random here.
# Then it will go over all of these groups and classifies them to the other 180 elements and sum the total errors.
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
return(sum(diag(confmat))/sum(confmat))
}
#run.analyse is used as the main function to run the analyse
#classifyInformation is used to store the parameters with the corresponding number of errors.
run.analyse <- function(data,k){
#get a random of size 200, first attribute of the data variable is the nr
classifyInformation = data.frame(k = c(), accuracy = c())
for(i in 1 : k){ # nmin and minleaf may have different range
value <- ten.fold.split(trainingSet,i) # total error for 10-fold validation
classifyInformation = rbind(classifyInformation, c(i, value))
}
names(classifyInformation) <- c("k","accuracy")
return(classifyInformation)
}
neighboursInformation <- run.analyse(digit.dat[train.index,],1)
run.analyse <- function(data,k){
#get a random of size 200, first attribute of the data variable is the nr
classifyInformation = data.frame(k = c(), accuracy = c())
for(i in 1 : k){ # nmin and minleaf may have different range
value <- ten.fold.split(data,i) # total error for 10-fold validation
classifyInformation = rbind(classifyInformation, c(i, value))
}
names(classifyInformation) <- c("k","accuracy")
return(classifyInformation)
}
neighboursInformation <- run.analyse(digit.dat[train.index,],1)
ten.fold.split(digit.dat[train.index,],1)
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
confmat <- lapply(confmat, as.numeric)
return(sum(diag(confmat))/sum(confmat))
}
ten.fold.split(digit.dat[train.index,],1)
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- lapply(confmat, as.numeric)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
return(sum(diag(confmat))/sum(confmat))
}
ten.fold.split(digit.dat[train.index,],1)
#ten.fold.split first divides the groups in equal divided groups of 20. The data is already random, so we do not make it random here.
# Then it will go over all of these groups and classifies them to the other 180 elements and sum the total errors.
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
return(confmat)
# return(sum(diag(confmat))/sum(confmat))
}
ten.fold.split(digit.dat[train.index,],1)
neighboursInformation <- run.analyse(digit.dat[train.index,],1)
b <- ten.fold.split(digit.dat[train.index,],1)
sum(diag(b))/sum(b)
sum(b)
diag(b)
b <- as.numeric(unlist(ab)
;
b <- as.numeric(unlist(b))
diag(b)
b <- ten.fold.split(digit.dat[train.index,],1)
b
b <- as.data.frame(b)
diag(b)
b
b <- lapply(a, as.numeric)
b <- lapply(b, as.numeric)
diag(b)
b[1,1]
as.data.frame(b)[1,1]
b <- as.data.frame(b)
b[1,1]
b
diag(b)
b <- apply(b, c(1,2) ,as.numeric)
diag(b)
b
b <- apply(as.data.frame(b), c(1,2) ,as.numeric)
b <- ten.fold.split(digit.dat[train.index,],1)
ba <- apply(as.data.frame(b), c(1,2) ,as.numeric)
b
ba
ba==b
b + 1
ba==b
b <- b + 1
ba==b
#ten.fold.split first divides the groups in equal divided groups of 20. The data is already random, so we do not make it random here.
# Then it will go over all of these groups and classifies them to the other 180 elements and sum the total errors.
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
#need to convert it to numeric, for some reason it is not numeric anymore
confmat <- apply(as.data.frame(confmat), c(1,2) ,as.numeric)
return(sum(diag(confmat))/sum(confmat))
}
ten.fold.split(digit.dat[train.index,],1)
neighboursInformation <- run.analyse(digit.dat[train.index,],1)
neighboursInformation
neighboursInformation <- run.analyse(digit.dat[train.index,],10)
neighboursInformation
neighboursInformation[min(neighboursInformation),]
sample(c(1:nrow(digit.dat)),1000)
length(sample(c(1:nrow(digit.dat)),1000))
digit.dat[-train.index,]
nrow(digit.dat[-train.index,])
nrow(digit.dat[-train.index,digit.dat$label==2])
nrow(digit.dat[-train.index,])
nrow(digit.dat[-train.index,digit.dat[-train.index,]$label==2])
a <- digit.dat[-train.index,]
a[,a$label==2]
nrow(a[a$label==2,])
a <- digit.dat[,]
nrow(a[a$label==2,])
multimodal.confmat.single
# make confusion matrix for predictions on test data
multimodal.confmat.single <- table(digit.test$label,digit.multinom.single.test.pred)
digit[train.index,]
a <- digit.dat[train.index,]
a <- digit.dat[-train.index,]
nrow(a[a$label==2,])
library(glmnet)
?cv.glmnet
#loading the data
digit.dat <- read.csv("dataset/mnist.csv", header = TRUE, sep = ",")
digit.dat$label = as.factor(digit.dat$label)
#remove all zero colls
digit.dat <- digit.dat[, colSums(digit.dat != 0) > 0]
set.seed(123456)
train.index <- sample(c(1:nrow(digit.dat)),1000)
#loading the data
digit.dat <- read.csv("dataset/mnist.csv", header = TRUE, sep = ",")
digit.dat$label = as.factor(digit.dat$label)
#remove all zero colls
digit.dat <- digit.dat[, colSums(digit.dat != 0) > 0]
#combine all the features
digit.all.features <- cbind(digit.dat,inkFeature,scaledHorizontalFeatures,scaledVerticalFeatures)
#All the features
inkDensity <- apply(digit.dat[,-1],1,sum)
inkMeanStats <- tapply(inkDensity,digit.dat$label,mean)
inkSdStats <- tapply(inkDensity,digit.dat$label,sd)
#scale features
ScaledinkSdStats <- scale(inkSdStats)
names(ScaledinkSdStats) <- 0:9
digit.ink <- cbind(digit.dat,inkFeature)
#combine features
#assign to each label to correct ink feature
inkFeature <- 1:nrow(digit.dat)
for(i in 1:nrow(digit.dat)){
inkFeature[i] <- ScaledinkSdStats[digit.dat[i,]$label]
}
generalLineFeatures <- function(lines,data,featureFrame){
i <- 0
for(elem in lines){
i <- i + 1
featureFrame[,i] <- horizontal_line(elem,data)
}
return(featureFrame)
}
horizontal_line <- function (b,data){
line = 1:42000
for(i in 1:42000){
line[i] = sum(data[i, ((b-1)*28+2) : ((b-1)*28 + 29)]);
}
line
} # to use the function, type digit.dat = cbind(digit.dat, horizontal_line(b, digit$dat)
vertical_line <- function (a, data){
line = 1:42000
for(i in 1:42000){
sumv = 0;
for(j in 0:27){
sumv = sumv + data[i, a + 28*j + 1];
}
line[i] = sumv;
}
line
} # to use the function, type digit.dat = cbind(digit.dat, vertical_line(a, digit$dat)
horizontalFrame <- data.frame("horizontal-8"=1:42000,"horizontal-12"=1:42000,"horizontal-14"=1:42000,"horizontal-16"=1:42000,"horizontal-20"=1:42000)
verticalFrame <- data.frame("vertical-10"=1:42000,"horizontal-12"=1:42000,"horizontal-14"=1:42000,"horizontal-16"=1:42000,"horizontal-20"=1:42000)
horizontalFeatures <- generalLineFeatures(horizontalLines,digit.dat,horizontalFrame)
verticalFeatures <- generalLineFeatures(verticalLines,digit.dat,verticalFrame)
generalLineFeatures <- function(lines,data,featureFrame){
i <- 0
for(elem in lines){
i <- i + 1
featureFrame[,i] <- horizontal_line(elem,data)
}
return(featureFrame)
}
horizontalFeatures <- generalLineFeatures(horizontalLines,digit.dat,horizontalFrame)
verticalFeatures <- generalLineFeatures(verticalLines,digit.dat,verticalFrame)
horizontalLines <- c(8,12,14,16,20)
verticalLines <- c(10,12,14,16,20)
horizontalFeatures <- generalLineFeatures(horizontalLines,digit.dat,horizontalFrame)
verticalFeatures <- generalLineFeatures(verticalLines,digit.dat,verticalFrame)
scaledHorizontalFeatures <- scale(horizontalFeatures)
scaledVerticalFeatures <- scale(verticalFeatures)
digit.all.features <- cbind(digit.dat,inkFeature,scaledHorizontalFeatures,scaledVerticalFeatures)
#All the fe
#training set
digit.train <- digit.all.features[train.index,]
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- digit.all.features[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
#run 10 fold  and determine the k with the best accuracy
neighboursInformation <- run.analyse(digit.dat[train.index,],30)
#ten.fold.split first divides the groups in equal divided groups of 20. The data is already random, so we do not make it random here.
# Then it will go over all of these groups and classifies them to the other 180 elements and sum the total errors.
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
set.seed(123456)
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
#need to convert it to numeric, for some reason it is not numeric anymore
confmat <- apply(as.data.frame(confmat), c(1,2) ,as.numeric)
return(sum(diag(confmat))/sum(confmat))
}
# listToVectorExpr is used to exclude one group of a list.
# The data parameter is a list of 10 groups and except is the number of the group to be excluded from tr. set
listToVectorExcept <- function(data, except){
value <- c()
for(i in 1:NROW(data)){
if(i != except){
value <- append(value, data[[i]])
}
}
return(value)
}
#run.analyse is used as the main function to run the analyse
#classifyInformation is used to store the parameters with the corresponding number of errors.
run.analyse <- function(data,k){
#get a random of size 200, first attribute of the data variable is the nr
classifyInformation = data.frame(k = c(), accuracy = c())
for(i in 1 : k){ # nmin and minleaf may have different range
value <- ten.fold.split(data,i) # total error for 10-fold validation
classifyInformation = rbind(classifyInformation, c(i, value))
}
names(classifyInformation) <- c("k","accuracy")
return(classifyInformation)
}
#run 10 fold  and determine the k with the best accuracy
neighboursInformation <- run.analyse(digit.dat[train.index,],30)
#one neighbor <- still need to use cross validation on this method.
set.seed(123456)
knn.pred <- knn(digit.train[,-1],digit.test[,-1],digit.train$label, k = 1)
knn.table <- table( digit.test$label, knn.pred)
# use it to compute accuracy on test data
sum(diag(confmat))/sum(confmat)
#k-nearest neigbhours
library(class)
#training set
#one neighbor <- still need to use cross validation on this method.
set.seed(123456)
neighboursInformation <- run.analyse(digit.dat[train.index,],30)
neighboursInformation
#run 10 fold  and determine the k with the best accuracy
neighboursInformation <- run.analyse(digit.dat[train.index,],100)
neighboursInformation
neighboursInformation[max(neighboursInformation$accuracy),]
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
set.seed(123456)
knn.pred <- knn(digit.train[,-1],digit.test[,-1],digit.train$label, k = 1)
knn.table <- table( digit.test$label, knn.pred)
# use it to compute accuracy on test data
sum(diag(confmat))/sum(confmat)
# confmat <- table( digit.test$label, knn.pred)
confmat
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
neighboursInformation
plot(neighboursInformation)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
sum(diag(confmat))/sum(confmat)
sum(diag(knn.table))/sum(knn.table)
threshold <- 100
x <- digit.dat[train.index,-1]
tmp <- apply(x,2,function(a){if(length(a[a!=0]) > threshold) a})
if(class(tmp) == "list"){
print("remove all null cases from the list")
tmp <- tmp[!sapply(tmp, is.null)]
}
tmp <- as.data.frame(tmp)
digit.noise.removed.train <- cbind(digit.dat[train.index,1],tmp,inkFeature[train.index],verticalFeatures[train.index,],horizontalFeatures[train.index,])
digit.noise.removed.test <- cbind(digit.dat[-train.index,1],digit.dat[-train.index,colnames(tmp)],inkFeature[-train.index],verticalFeatures[-train.index,],horizontalFeatures[-train.index,])
colnames(digit.noise.removed.train)[1] <- "label"
colnames(digit.noise.removed.test) <- colnames(digit.noise.removed.train)
digit.train <- digit.noise.removed.train
digit.train$label = as.factor(digit.noise.removed$label)
#test set
digit.test <- digit.noise.removed.test
digit.test$label = as.factor(digit.svn.test$label)
digit.train <- digit.noise.removed.train
digit.train$label = as.factor(digit.noise.removed$label)
digit.test <- digit.all.features[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
digit.test <- digit.all.features[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
#training set
digit.train <- digit.all.features[train.index,]
digit.train$label = as.factor(digit.train$label)
digit.noise.removed.train <- cbind(digit.dat[train.index,1],tmp,inkFeature[train.index],verticalFeatures[train.index,],horizontalFeatures[train.index,])
digit.noise.removed.test <- cbind(digit.dat[-train.index,1],digit.dat[-train.index,colnames(tmp)],inkFeature[-train.index],verticalFeatures[-train.index,],horizontalFeatures[-train.index,])
colnames(digit.noise.removed.train)[1] <- "label"
colnames(digit.noise.removed.test) <- colnames(digit.noise.removed.train)
#training set
digit.train <- digit.noise.removed.train
digit.train$label = as.factor(digit.noise.removed$label)
#test set
digit.test <- digit.noise.removed.test
digit.test$label = as.factor(digit.test$label)
digit.train$label = as.factor(digit.noise.removed$label)
digit.train <- digit.noise.removed.train
digit.train$label = as.factor(digit.noise.removed.train$label)
digit.test <- digit.noise.removed.test
digit.test$label = as.factor(digit.test$label)
neighboursInformation <- run.analyse(digit.dat[train.index,],10)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
neighboursInformation <- run.analyse(digit.train,10)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
set.seed(123456)
knn.pred <- knn(digit.train[,-1],digit.test[,-1],digit.train$label, k = 1)
knn.table <- table( digit.test$label, knn.pred)
sum(diag(knn.table))/sum(knn.table)
digit.ink <- cbind(digit.dat$label,inkFeature)
#training set
digit.train <- digit.ink[train.index,]
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- digit.ink[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
digit.train <- digit.ink[train.index,]
digit.train$label = as.factor(digit.train$label)
digit.train <- digit.ink[train.index,]
digit.train$label = as.factor(digit.train$label)
digit.ink
colnames(digit.ink)[1] <- "label"
digit.train <- digit.ink[train.index,]
digit.train$label = as.factor(digit.train$label)
View(digit.train)
digit.train <- digit.ink[train.index,]
View(digit.train)
class(digit.train)
digit.train <- as.data.frame(digit.ink[train.index,])
digit.train$label = as.factor(digit.train$label)
digit.test <- digit.ink[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
#test set
digit.test <- as.data.frame(digit.ink[-train.index,colnames(digit.train)])
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 100000, MaxNWts = 100000000000000)
library(nnet)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 100000, MaxNWts = 100000000000000)
nrow(digit.train)
# fit multinomial logistic regression model
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
digit.multinom.pred <- predict(digit.multinom, digit.test[,-1],type="class")
nrow(digit.test)
nrow(digit.train)
apply(digit.train, 2, function(x) any(is.na(x)))
apply(digit.test, 2, function(x) any(is.na(x)))
# predict class label on training data
digit.multinom.pred <- predict(digit.multinom, digit.test[,-1],type="class")
digit.ink.horizontal <- cbind(digit.ink,horizontalFeature)
#training set
digit.train <- as.data.frame(digit.ink[train.index,])
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- as.data.frame(digit.ink[-train.index,colnames(digit.train)])
digit.test$label = as.factor(digit.test$label)
digit.ink.horizontal <- cbind(digit.ink,horizontalFeature)
horizontalLines <- c(8,12,14,16,20)
verticalLines <- c(10,12,14,16,20)
horizontalFeatures <- generalLineFeatures(horizontalLines,digit.dat,horizontalFrame)
verticalFeatures <- generalLineFeatures(verticalLines,digit.dat,verticalFrame)
scaledHorizontalFeatures <- scale(horizontalFeatures)
scaledVerticalFeatures <- scale(verticalFeatures)
horizontalFrame <- data.frame("horizontal-8"=1:42000,"horizontal-12"=1:42000,"horizontal-14"=1:42000,"horizontal-16"=1:42000,"horizontal-20"=1:42000)
verticalFrame <- data.frame("vertical-10"=1:42000,"horizontal-12"=1:42000,"horizontal-14"=1:42000,"horizontal-16"=1:42000,"horizontal-20"=1:42000)
generalLineFeatures <- function(lines,data,featureFrame){
i <- 0
for(elem in lines){
i <- i + 1
featureFrame[,i] <- horizontal_line(elem,data)
}
return(featureFrame)
}
horizontal_line <- function (b,data){
line = 1:42000
for(i in 1:42000){
line[i] = sum(data[i, ((b-1)*28+2) : ((b-1)*28 + 29)]);
}
line
} # to use the function, type digit.dat = cbind(digit.dat, horizontal_line(b, digit$dat)
vertical_line <- function (a, data){
line = 1:42000
for(i in 1:42000){
sumv = 0;
for(j in 0:27){
sumv = sumv + data[i, a + 28*j + 1];
}
line[i] = sumv;
}
line
}
digit.ink <- cbind(digit.dat,inkFeature)
#training set
digit.train <- as.data.frame(digit.ink[train.index,])
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- as.data.frame(digit.ink[-train.index,colnames(digit.train)])
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
digit.multinom.pred <- predict(digit.multinom, digit.test[,-1],type="class")
digit.ink <- cbind(digit.dat[,1],inkFeature)
colnames(digit.ink)[1] <- "label"
digit.train <- as.data.frame(digit.ink[train.index,])
digit.train$label = as.factor(digit.train$label)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
# predict class label on training data
digit.multinom.pred <- predict(digit.multinom, digit.test[,-1],type="class")
table(digit.train$label,digit.multinom.pred)
digit.multinom.pred <- predict(digit.multinom, digit.test[,-1],type="class")
table(digit.train$label,digit.multinom.pred)
digit.test <- as.data.frame(digit.ink[-train.index,colnames(digit.train)])
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = scale(digit.train), maxit = 10000000, MaxNWts = 100000000000000)
save.image("D:/Development/School/Pattern-Recognition/Exercise/ijkok-backup.RData")
