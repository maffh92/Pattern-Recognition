digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
predict class label on training data
digit.multinom.pred <- predict(digit.multinom, digit.test[,-1],type="class")
digitTest <- as.data.frame(digit.test[,-1])
digit.multinom.pred <- predict(digit.multinom, digitTest,type="class")
digitTest <- as.data.frame(digit.test[,-1])
colnames(digitTest)[1] <- "V1"
# predict class label on test data
digit.multinom.single.test.pred <- predict(digit.multinom, digit.test[,-1],type="class")
is.na(c(1,2,3))
is.na(c(1,2,NA))
apply(digitTest,2, is.na)
gotNa <- apply(digitTest,2, is.na)
gotNa[,gotNa==TRue]
gotNa[,gotNa==TRUE]
gotNa[,gotNa[1]==TRUE]
gotNa[gotNa[1]==TRUE,]
gotNa[gotNa[1]==TRUE]
gotNa[gotNa[1]==false]
gotNa[gotNa[1]==FALSE]
gotNa[gotNa[1]==TRUE]
digitTest <- as.data.frame(digit.test[,-1])
colnames(digitTest)[1] <- "V1SAODK"
gotNa <- apply(digitTest,2, is.na)
length(gotNa[gotNa==TRUE])
length(gotNa[gotNa==FALSE])
# predict class label on test data
digit.multinom.single.test.pred <- predict(digit.multinom, digitTest,type="class"
)
digitTest <- as.data.frame(digit.test[,-1])
colnames(digitTest)[1] <- "V1"
table(digit.train$label,digit.multinom.pred)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
digit.multinom.single.test.pred <- predict(digit.multinom, digitTest,type="class")
dim(digit.train)
View(digit.train[1:10,])
dim(digit.test)
View(digit.test[1:10,])
digit.multinom.single.test.pred <- predict(digit.multinom, digit.train,type="class")
table(digit.test$label,digit.multinom.single.test.pred)
digit.multinom.single.test.pred <- predict(digit.multinom, digit.test,type="class")
table(digit.test$label,digit.multinom.single.test.pred)
# make confusion matrix for predictions on test data
multimodal.confmat.single <- table(digit.test$label,digit.multinom.single.test.pred)
sum(diag(multimodal.confmat.single))/sum(multimodal.confmat.single)
str(digit.train)
str(digit.test)
set.seed(123456)
train.index <- sample(c(1:nrow(digit.dat)),1000)
#loading the data
digit.dat <- read.csv("dataset/mnist.csv", header = TRUE, sep = ",")
digit.dat$label = as.factor(digit.dat$label)
digit.dat <- read.csv("dataset/mnist.csv", header = TRUE, sep = ",")
digit.dat$label = as.factor(digit.dat$label)
set.seed(123456)
train.index <- sample(c(1:nrow(digit.dat)),1000)
inkDensity <- apply(digit.dat[,-1],1,sum)
inkMeanStats <- tapply(inkDensity,digit.dat$label,mean)
inkSdStats <- tapply(inkDensity,digit.dat$label,sd)
#scale features
ScaledinkSdStats <- scale(inkSdStats)
names(ScaledinkSdStats) <- 0:9
digit.ink <- cbind(digit.dat,inkFeature)
#combine features
#assign to each label to correct ink feature
inkFeature <- 1:nrow(digit.dat)
for(i in 1:nrow(digit.dat)){
inkFeature[i] <- ScaledinkSdStats[digit.dat[i,]$label]
}
digit.ink <- cbind(digit.dat,inkFeature)
library(nnet)
digit.ink <- cbind(digit.dat[,1],inkFeature)
colnames(digit.ink)[1] <- "label"
#training set
digit.train <- as.data.frame(digit.ink[train.index,])
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- as.data.frame(digit.ink[-train.index,colnames(digit.train)])
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
digit.ink[digit.ink$label=1,]
digit.ink[digit.ink$label==1,]
digit.ink[digit.ink[1,]==1,]
View(digit.ink)
digit
digit.ink$label
digit.ink[,1]
digit.ink[digit.ink[,1]==1,]
#All the features
inkDensity <- apply(digit.dat[,-1],1,sum)
inkMeanStats <- tapply(inkDensity,digit.dat$label,mean)
inkSdStats <- tapply(inkDensity,digit.dat$label,sd)
#scale features
ScaledMeanSdStats <- scale(inkMeanStats)
names(ScaledMeanSdStats) <- 0:9
#combine features
#assign to each label to correct ink feature
inkFeature <- 1:nrow(digit.dat)
for(i in 1:nrow(digit.dat)){
inkFeature[i] <- ScaledMeanSdStats[digit.dat[i,]$label]
}
library(nnet)
digit.ink <- cbind(digit.dat[,1],inkFeature)
colnames(digit.ink)[1] <- "label"
#training set
digit.train <- as.data.frame(digit.ink[train.index,])
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- as.data.frame(digit.ink[-train.index,colnames(digit.train)])
digit.test$label = as.factor(digit.test$label)
# fit multinomial logistic regression model
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.train, maxit = 10000000, MaxNWts = 100000000000000)
# predict class label on test data
digit.multinom.single.test.pred <- predict(digit.multinom, digit.test,type="class")
table(digit.test$label,digit.multinom.single.test.pred)
digit.train <- digit.train[train.index,]
digit.train$label <- as.factor(digit.train$inkFeature)
digit.test <- digit.train[train.index,]
digit.test$label <- as.factor(digit.test$label)
#All the features
inkDensity.train <- apply(digit.train[,-1],1,sum)
inkMeanStats.train <- tapply(inkDensity,digit.train$label,mean)
inkSdStats.train <- tapply(inkDensity,digit.train$label,sd)
inkDensity.train <- apply(digit.train[,-1],1,sum)
digit.train <- digit.train[train.index,]
digit.train$label <- as.factor(digit.train$inkFeature)
digit.test <- digit.train[train.index,]
digit.test$label <- as.factor(digit.test$label)
dim(digit.train)
inkMeanStats.train <- tapply(inkDensity,digit.train$label,mean)
inkSdStats.train <- tapply(inkDensity,digit.train$label,sd)
inkMeanStats.train <- tapply(inkDensity.train,digit.train$label,mean)
inkSdStats.train <- tapply(inkDensity.train,digit.train$label,sd)
inkMeanStats.train <- tapply(inkDensity.train,digit.train$label,mean)
inkDensity.train <- apply(digit.train[,-1],1,sum)
dim(digit.train)
#loading the data
digit.dat <- read.csv("dataset/mnist.csv", header = TRUE, sep = ",")
digit.dat$label = as.factor(digit.dat$label)
set.seed(123456)
train.index <- sample(c(1:nrow(digit.dat)),1000)
digit.train <- digit.train[train.index,]
digit.train$label <- as.factor(digit.train$inkFeature)
digit.test <- digit.train[train.index,]
digit.test$label <- as.factor(digit.test$label)
digit.train <- digit.dat[train.index,]
digit.train <- digit.dat[train.index,]
digit.train$label <- as.factor(digit.train$inkFeature)
digit.test <- digit.dat[train.index,]
digit.train$label <- as.factor(digit.train$inkFeature)
digit.train <- digit.dat[train.index,]
digit.train$label <- as.factor(digit.train$label)
digit.test <- digit.dat[train.index,]
digit.test$label <- as.factor(digit.test$label)
#All the features
inkDensity.train <- apply(digit.train[,-1],1,sum)
inkMeanStats.train <- tapply(inkDensity.train,digit.train$label,mean)
inkSdStats.train <- tapply(inkDensity.train,digit.train$label,sd)
ScaledMeanSdStats.train <- scale(inkMeanStats.train)
names(ScaledMeanSdStats.train) <- 0:9
inkFeature.train <- 1:nrow(digit.train)
inkFeature.train <- 1:nrow(digit.train)
for(i in 1:nrow(digit.train)){
inkFeature[i] <- ScaledMeanSdStats[digit.dat[i,]$label]
}
#assign to each label to correct ink feature
inkFeature.train <- 1:nrow(digit.train)
for(i in 1:nrow(digit.train)){
inkFeature.train[i] <- ScaledMeanSdStats.train[digit.dat[i,]$label]
}
digit.ink.train <- cbind(digit.dat,inkFeature)
#All the features
inkDensity.train <- apply(digit.train[,-1],1,sum)
inkMeanStats.train <- tapply(inkDensity.train,digit.train$label,mean)
inkSdStats.train <- tapply(inkDensity.train,digit.train$label,sd)
#scale features
ScaledMeanSdStats.train <- scale(inkMeanStats.train)
names(ScaledMeanSdStats.train) <- 0:9
#combine features
#assign to each label to correct ink feature
inkFeature.train <- 1:nrow(digit.train)
for(i in 1:nrow(digit.train)){
inkFeature.train[i] <- ScaledMeanSdStats.train[digit.dat[i,]$label]
}
digit.ink.train <- cbind(digit.train,inkFeature.train)
for(i in 1:nrow(digit.train)){
inkFeature.train[i] <- ScaledMeanSdStats.train[digit.train[i,]$label]
}
#All the features
inkDensity.test <- apply(digit.test[,-1],1,sum)
inkMeanStats.test <- tapply(inkDensity.test,digit.test$label,mean)
inkSdStats.test <- tapply(inkDensity.test,digit.test$label,sd)
#scale features
ScaledMeanSdStats.test <- scale(inkMeanStats.test)
names(ScaledMeanSdStats.test) <- 0:9
#combine features
#assign to each label to correct ink feature
inkFeature.test <- 1:nrow(digit.test)
for(i in 1:nrow(digit.test)){
inkFeature.test[i] <- ScaledMeanSdStats.test[digit.test[i,]$label]
}
digit.ink.test <- cbind(digit.test,inkFeature.test)
set.seed(123456)
digit.multinom <- multinom(label ~ ., data = digit.ink.train, maxit = 10000000, MaxNWts = 100000000000000)
# ensure the results are repeatable
set.seed(123456)
# load the library
library(mlbench)
library(caret)
install.packages(mlbrench)
install.packages("mlbrench")
install.packages("mlbench")
install.packages("caret")
?rfeControl
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
set.seed(123456)
# load the library
library(mlbench)
library(caret)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(PimaIndiansDiabetes[,1:8], PimaIndiansDiabetes[,9], sizes=c(1:8), rfeControl=control)
results <- rfe(digit.dat[,-1], digit.dat$label, sizes=c(1:300), rfeControl=control)
library(e1071)
install.packages("e1071")
library(e1071)
results <- rfe(digit.dat[,-1], digit.dat$label, sizes=c(1:300), rfeControl=control)
library(randomForest)
install.packages("randomForest")
library(randomForest)
# run the RFE algorithm
results <- rfe(digit.dat[,-1], digit.dat$label, sizes=c(1:300), rfeControl=control)
digit.dat <- read.csv("dataset/mnist.csv", header = TRUE, sep = ",")
digit.dat$label = as.factor(digit.dat$label)
set.seed(123456)
train.index <- sample(c(1:nrow(digit.dat)),1000)
inkDensity <- apply(digit.dat[,-1],1,sum)
horizontalFeatures <- generalLineFeatures(horizontalLines,digit.dat,horizontalFrame)
verticalFeatures <- generalLineFeatures(verticalLines,digit.dat,verticalFrame)
ncol(digit.train)
nrow(digit.train)
set.seed(123456)
# load the library
library(mlbench)
library(caret)
library(e1071)
library(randomForest)
# load the data
data(PimaIndiansDiabetes)
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(1:300), rfeControl=control)
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(1:5), rfeControl=control)
print(results)
results$optVariables
results$variables
results$results
results$results[,1]
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(1:8), rfeControl=control)
# summarize the results
results$results[,1]
length(results$results[,1])
predictors(results)
plot(results, type=c("g", "o"))
load("~/Development/Pattern-Recognition/Exercise/ijkok-backup.RData")
digit.all.features.rawPixel = as.data.frame(cbind(digit.dat, inkFeature, scaledHorizontalFeatures, scaledVerticalFeatures))
digit.train <- digit.all.features.rawPixel[train.index,]
digit.train$label = as.factor(digit.train$label)
set.seed(123456)
# load the library
library(mlbench)
library(caret)
library(e1071)
library(randomForest)
# load the data
data(PimaIndiansDiabetes)
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(300:350,400,450,500,550,600,650,700,750), rfeControl=control)
ncol(digit.train)
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(300,350,400,450,500,550,600,650), rfeControl=control)
print(results)
plot(results, type=c("g", "o"))
results$bestSubset
results$maximize
results$results
results$fit
results$variables
View(results$variables)
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(300), rfeControl=control)
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(350), rfeControl=control)
print(results)
results$variables
results$results
results$bestSubset
results$fit
results$pred
results$results
results$optVariables
length(results$optVariables)
results$optVariables
results <- rfe(digit.train[,-1], digit.train$label, sizes=c(10,350), rfeControl=control)
print(results)
# list the chosen features
predictors(results)
predictors(results)
length(predictors(results))
print(results)
sum(digit.dat$pixel91)
sum(digit.dat$pixel226)
predictors(results)
predictors(results)[1:300]
subset.selection.varnames <- predictors(results)[1:300]
library(glmnet)
predictors(results)[1:300]
install.packages("glmnet")
#training set
digit.train <- digit.all.features.rawPixel[train.index,subset.selection.varnames]
digit.train$label = as.factor(digit.train$label)
digit.train <- digit.all.features.rawPixel[train.index,c("label",subset.selection.varnames)]
digit.train$label = as.factor(digit.train$label)
digit.test <- digit.all.features.rawPixel[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
library(glmnet)
set.seed(123456)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
plot(digit.lasso.cv)
digit.lasso.cv.pred <- predict(digit.lasso.cv, as.matrix(digit.test[,-1]),type="class")
digit.lasso.cv.confmat <- table(digit.test$label,digit.lasso.cv.pred)
digit.lasso.cv.confmat
sum(diag(digit.lasso.cv.confmat))/sum(digit.lasso.cv.confmat)
#training set
digit.train <- digit.all.features.rawPixel[train.index,]
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- digit.all.features.rawPixel[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
plot(digit.lasso.cv)
# predict class label on test set using the best cv model
digit.lasso.cv.pred <- predict(digit.lasso.cv, as.matrix(digit.test[,-1]),type="class")
digit.lasso.cv.confmat <- table(digit.test$label,digit.lasso.cv.pred)
digit.lasso.cv.confmat
sum(diag(digit.lasso.cv.confmat))/sum(digit.lasso.cv.confmat)
#training set
digit.train <- digit.all.features.rawPixel[train.index,c("label",subset.selection.varnames)]
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- digit.all.features.rawPixel[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
plot(digit.lasso.cv)
# predict class label on test set using the best cv model
digit.lasso.cv.pred <- predict(digit.lasso.cv, as.matrix(digit.test[,-1]),type="class")
subset.selection.varnames <- predictors(results)[1:350]
digit.train <- digit.all.features.rawPixel[train.index,c("label",subset.selection.varnames)]
digit.train$label = as.factor(digit.train$label)
#test set
digit.test <- digit.all.features.rawPixel[-train.index,colnames(digit.train)]
digit.test$label = as.factor(digit.test$label)
set.seed(123456)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
plot(digit.lasso.cv)
digit.lasso.cv.pred <- predict(digit.lasso.cv, as.matrix(digit.test[,-1]),type="class")
# mak
digit.lasso.cv.confmat <- table(digit.test$label,digit.lasso.cv.pred)
digit.lasso.cv.confmat
digit.lasso.cv.pred
sum(diag(digit.lasso.cv.confmat))/sum(digit.lasso.cv.confmat)
#run.analyse is used as the main function to run the analyse
#classifyInformation is used to store the parameters with the corresponding number of errors.
run.analyse <- function(data,k){
#get a random of size 200, first attribute of the data variable is the nr
classifyInformation = data.frame(k = c(), accuracy = c())
for(i in 1 : k){ # nmin and minleaf may have different range
value <- ten.fold.split(data,i) # total error for 10-fold validation
classifyInformation = rbind(classifyInformation, c(i, value))
}
names(classifyInformation) <- c("k","accuracy")
return(classifyInformation)
}
#ten.fold.split first divides the groups in equal divided groups of 20. The data is already random, so we do not make it random here.
# Then it will go over all of these groups and classifies them to the other 180 elements and sum the total errors.
ten.fold.split <- function(data,k){ # returns total error for 10-fold validation
rowsToDivide <- 1 : nrow(data)
#split the data set into equal divided groups
equalDividedGroups <- split(rowsToDivide, ceiling(seq_along(rowsToDivide)/100)) #
confmat <- data.frame("0"=rep(0,10),"1"=rep(0,10),"2"=rep(0,10),"3"=rep(0,10),"4"=rep(0,10),"5"=rep(0,10),"6"=rep(0,10),"7"=rep(0,10),"8"=rep(0,10),"9"=rep(0,10))
colnames(confmat) <- 0:9
for(i in 1:NROW(equalDividedGroups)){
#split the training set and testset
trainingSet <- data[listToVectorExcept(equalDividedGroups,i),]
testSet <- data[equalDividedGroups[[i]],]
set.seed(123456)
knn.pred <- knn(trainingSet[,-1],testSet[,-1],trainingSet[,1], k = k)
confmat <- confmat + table(testSet[,1], knn.pred)
# use it to compute accuracy on test data
}
#need to convert it to numeric, for some reason it is not numeric anymore
confmat <- apply(as.data.frame(confmat), c(1,2) ,as.numeric)
return(sum(diag(confmat))/sum(confmat))
}
# listToVectorExpr is used to exclude one group of a list.
# The data parameter is a list of 10 groups and except is the number of the group to be excluded from tr. set
listToVectorExcept <- function(data, except){
value <- c()
for(i in 1:NROW(data)){
if(i != except){
value <- append(value, data[[i]])
}
}
return(value)
}
#run.analyse is used as the main function to run the analyse
#classifyInformation is used to store the parameters with the corresponding number of errors.
run.analyse <- function(data,k){
#get a random of size 200, first attribute of the data variable is the nr
classifyInformation = data.frame(k = c(), accuracy = c())
for(i in 1 : k){ # nmin and minleaf may have different range
value <- ten.fold.split(data,i) # total error for 10-fold validation
classifyInformation = rbind(classifyInformation, c(i, value))
}
names(classifyInformation) <- c("k","accuracy")
return(classifyInformation)
}
#run 10 fold  and determine the k with the best accuracy
neighboursInformation <- run.analyse(digit.train,10)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
#k-nearest neigbhours
library(class)
#run 10 fold  and determine the k with the best accuracy
neighboursInformation <- run.analyse(digit.train,10)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
neighboursInformation
neighboursInformation <- run.analyse(digit.train,100)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
set.seed(123456)
knn.pred <- knn(digit.train[,-1],digit.test[,-1],digit.train$label, k = 1)
knn.table <- table( digit.test$label, knn.pred)
# use it to compute accuracy on test data
sum(diag(knn.table))/sum(knn.table)
knn.table
sum(diag(knn.table))/sum(knn.table)
digit.tune.svm <- tune.svm(digit.train[, -1],digit.train$label, cost=1:10)
# make predictions on test set
svm.pred <- predict(digit.svm, digit.test[,-1])
digit.svm
digit.tune.svm
digit.tune.svm$best.parameters
digit.tune.svm$performances
# Cost=1
digit.svm <- svm(digit.train[, -1],digit.train$label,cost=3)
svm.pred <- predict(digit.svm, digit.test[,-1])
svm.pred.table <- table(digit.svn.test$label,svm.pred)
svm.pred.table <- table(digit.test$label,svm.pred)
svm.pred.table <- table(digit.test$label,svm.pred)
svm.pred
svm.pred.table
sum(diag(svm.pred.table))/nrow(svm.pred.table)
svm.pred.table <- table(digit.test$label,svm.pred)
svm.pred.table
sum(diag(svm.pred.table))/sum(svm.pred.table)
save.image("~/Development/Pattern-Recognition/Exercise/ijkok-backup.RData")
digit.lasso.cv.confmat
sum(diag(digit.lasso.cv.confmat))/sum(digit.lasso.cv.confmat)
digit.lasso.cv.confmat
confmat
knn.table
neighboursInformation <- run.analyse(digit.train,100)
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
set.seed(123456)
knn.pred <- knn(digit.train[,-1],digit.test[,-1],digit.train$label, k = 3)
knn.table <- table( digit.test$label, knn.pred)
sum(diag(knn.table))/sum(knn.table)
knn.table <- table( digit.test$label, knn.pred)
knn.table
sum(diag(knn.table))/sum(knn.table)
<- table(digit.test$label,digit.lasso.cv.pred)
digit.lasso.cv.confmat
digit.tune.svm$performances
plot(neighboursInformation)
plot(neighboursInformation)
plot(digit.lasso.cv)
set.seed(123456)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
library(glmnet)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
set.seed(123456)
digit.lasso.cv <- cv.glmnet(as.matrix(digit.train[,-1]), digit.train$label,family="multinomial", type.measure="class")
plot(digit.lasso.cv)
digit.lasso.cv$lambda
digit.lasso.cv$lambda.min
digit.lasso.cv$lambda
digit.lasso.cv$lambda.1se
digit.lasso.cv$lambda.min
neighboursInformation[max(neighboursInformation$accuracy) == neighboursInformation$accuracy,]
sum(diag(knn.table))/sum(knn.table)
digit.svm <- svm(digit.train[, -1],digit.train$label,cost=2)
library("e1071")
digit.svm <- svm(digit.train[, -1],digit.train$label,cost=2)
svm.pred <- predict(digit.svm, digit.test[,-1])
svm.pred.table <- table(digit.test$label,svm.pred)
sum(diag(svm.pred.table))/sum(svm.pred.table)
svm.pred.table
sum(diag(svm.pred.table))/sum(svm.pred.table)
